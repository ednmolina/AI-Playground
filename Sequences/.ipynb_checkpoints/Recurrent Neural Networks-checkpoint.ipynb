{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A characteristics of many neural networks such as densely connected networks or covnets is that they ave no memory. Each input shown to them is processed independently with no state kept in between inputs. In order to process sequences with these networks the whole sequence must be fed into the network at one and turn it to a single data point. They are what is called *feedforeward networks*.\n",
    "\n",
    "*Recurrent Neural Networks* solve this problem by processesing sequences by iterating through the sequence elements and maintaining a *state* containing information relative to what it has seen so far. In essence an RNN is a type of neural network that has an internal loop and the state of the rnn is reset between processing two different independent sequences. This means that a single sequence is considered a single data point. What changes is that this data point is no longer processed in a single step, rather the network will internally loop over the sequence elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy Implementation of a Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the number of timesteps in the input sequence\n",
    "timesteps = 100\n",
    "# Dimensionality of the input feature space; number of features\n",
    "input_features = 32\n",
    "# Dimensionality of the output feature space\n",
    "output_features = 64\n",
    "\n",
    "# Input data: random noise\n",
    "inputs = np.random.random((timesteps, input_features))\n",
    "# Initial state: all zeros\n",
    "state_t = np.zeros((output_features,))\n",
    "\n",
    "# Random weight matricies\n",
    "W = np.random.random((output_features, input_features))\n",
    "U = np.random.random((output_features, output_features))\n",
    "b = np.random.random((output_features,))\n",
    "\n",
    "# The input_t is a vector of shape (input_features,)\n",
    "sucessive_outputs = []\n",
    "for input_t in inputs:\n",
    "    # Combines the input with the current state (previous output)\n",
    "    # to obtain the current outputl this is the step function that\n",
    "    # characterizes RNNs\n",
    "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
    "    # Stores this output in a list\n",
    "    sucessive_outputs.append(output_t)\n",
    "    # Updates the state of the network for the next step\n",
    "    state_t = output_t\n",
    "\n",
    "# The output of the RNN is a 2D tensor with shape (timesteps, output_features)\n",
    "final_output_sequence = np.concatenate(sucessive_outputs, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
