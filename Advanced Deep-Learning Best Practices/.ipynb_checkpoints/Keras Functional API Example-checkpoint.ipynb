{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Functional API for Multi-Input Neural Networks\n",
    "This notebook will demonstrate how to load numerical, categorical, and image data, preprocessit, and use it for a multi-input model for Keras.\n",
    "\n",
    "Examples of Data Types:\n",
    "    * Numeric/Continuous Values: age, heart rate, blood pressure\n",
    "    * Categorical Values: gender, ethnicity\n",
    "    * Image Data: MRI, X-Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import locale\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the directory of the dataset\n",
    "Data_Directory = '/Users/edenmolina/Documents/AI-Playground/Houses Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will load the data and return only zipcodes with <25 houses\n",
    "def load_house_attributes(inputPath, cols):\n",
    "    \"\"\"\n",
    "    inputPath: string path to the text file containing the house data\n",
    "    cols: array of column names\n",
    "    \"\"\"\n",
    "    # Set column names and load the text data\n",
    "    cols = cols\n",
    "    df = pd.read_csv(inputPath, sep=\" \", header=None, names=cols)\n",
    "\n",
    "    # determine (1) the unique zip codes and (2) the number of data\n",
    "    # points with each zip code\n",
    "    zipcodes = df[\"zipcode\"].value_counts().keys().tolist()\n",
    "    counts = df[\"zipcode\"].value_counts().tolist()\n",
    "\n",
    "    # loop over each of the unique zip codes and their corresponding\n",
    "    # count\n",
    "    for (zipcode, count) in zip(zipcodes, counts):\n",
    "        # the zip code counts for our housing dataset is *extremely*\n",
    "        # unbalanced (some only having 1 or 2 houses per zip code)\n",
    "        # so let's sanitize our data by removing any houses with less\n",
    "        # than 25 houses per zip code\n",
    "        if count < 25:\n",
    "            idxs = df[df[\"zipcode\"] == zipcode].index\n",
    "            df.drop(idxs, inplace=True)\n",
    "\n",
    "    # return dataframe with houses with less than 25 houses per zipcode\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will process the normalize the data and one hot encode the zipcodes and create training and testing data\n",
    "def process_house_attributes(df, train, test, continuous_columns):\n",
    "    # Initiates the column names of the continuous data\n",
    "    continuous = continuous_columns\n",
    "    print ('Continuous COl', continuous)\n",
    "    # Perform min-max scaling so each feature value is [0, 1]\n",
    "    cs = MinMaxScaler()\n",
    "    trainContinuous = cs.fit_transform(train[continuous])\n",
    "    testContinuous = cs.transform(test[continuous])\n",
    "    \n",
    "    # One-hot encode the zip code categorical data\n",
    "    zipBinarizer = LabelBinarizer().fit(df['zipcode'])\n",
    "    trainCategorical = zipBinarizer.transform(train['zipcode'])\n",
    "    testCategorical = zipBinarizer.transform(test['zipcode'])\n",
    "    \n",
    "    # Stack the data together\n",
    "    trainX = np.hstack([trainCategorical, trainContinuous])\n",
    "    testX = np.hstack([testCategorical, trainContinuous])\n",
    "    \n",
    "    return (trainX, testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will load the images, generate a montage image from the four images\n",
    "# images will be arranged from bathroom, bedroom, kichen, frontal\n",
    "# append all home montage from four photos\n",
    "def load_house_images(df, inputPath):\n",
    "    \"\"\"\n",
    "    df: pandas dataframe of house data\n",
    "    inputPath: path to the dataset\n",
    "    \"\"\"\n",
    "    # initialize our images\n",
    "    images = []\n",
    "    \n",
    "    # Loop over the indecies of the houses\n",
    "    for i in df.index.values:\n",
    "        # find four images for the house and sort by file path\n",
    "        # ensure that the four images are ALWAYS in the same order\n",
    "        basePath = os.path.sep.join([inputPath, \"{}_*\".format(i + 1)])\n",
    "\n",
    "        housePaths = sorted(list(glob.glob(basePath)))\n",
    "\n",
    "        # Initialize list of input images along with the output image\n",
    "        # Images are in color, there fore there are 3 channels\n",
    "        inputImages = []\n",
    "        outputImage = np.zeros((64, 64, 3), dtype = 'uint8')\n",
    "\n",
    "        # Loop over the input house paths\n",
    "        for housePath in housePaths:\n",
    "            image = cv2.imread(housePath)\n",
    "\n",
    "            # resize image\n",
    "            image = cv2.resize(image, (32, 32))\n",
    "            inputImages.append(image)\n",
    "\n",
    "            # tile the four images in the output image\n",
    "            # first image goes in top-right\n",
    "            # second image goes in top left\n",
    "            # third image goes in bottom right\n",
    "            # fourth goes in bottom left\n",
    "\n",
    "        outputImage[0:32, 0:32] = inputImages[0]\n",
    "        outputImage[0:32, 32:64] = inputImages[1]\n",
    "        outputImage[32:64, 32:64] = inputImages[2]\n",
    "        outputImage[32:64, 0:32] = inputImages[3]\n",
    "\n",
    "        # add tiled image to the set of images the network will be trained on\n",
    "        images.append(outputImage)\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Multi-Layer Perceptron (MLP) and Convolutional Neural Network (Covnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress = False):\n",
    "    \"\"\"\n",
    "    Create layers of Multi-Layer Perceptron\n",
    "    can return tensor dim 8 or can regress to output scalar\n",
    "    \"\"\"\n",
    "    # Define MLP as 2 dense layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = dim, activation = 'relu'))\n",
    "    model.add(Dense(4, activation = 'relu'))\n",
    "    \n",
    "    # Check if regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        \n",
    "    # Return the Model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters = (16, 32, 64), regress = False):\n",
    "    \"\"\"\n",
    "    Handles the image data\n",
    "    width: int width of the input image in pixels\n",
    "    height: int height of the input image in pixels\n",
    "    depth: int number of channels in image (for RGB it is 3)\n",
    "    filters: tuple of progressively larger filters to the network can learn to discriminate features\n",
    "    regress: bool inidicating whether or not a fully connected linear activation layer will be appended to the CNN for regression\n",
    "    \"\"\"\n",
    "    # Initialize input shape and channel dimension\n",
    "    # Assumes a 'channels last' ordering for the TensorFlow backend\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "    \n",
    "    # Model Input\n",
    "    inputs = Input(shape = inputShape)\n",
    "    \n",
    "    # Loop over the filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        # If this is the first convolutional layer then set the input accordingly\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "        \n",
    "        # Conv > Relu > BN > Pool\n",
    "        x = Conv2D(f, (3, 3), padding = 'same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis = chanDim)(x)\n",
    "        x = MaxPooling2D(pool_size = (2, 2))(x)\n",
    "        \n",
    "        # Flatten the volume\n",
    "        # FC > Relu > BN > Dropout\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(16)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = BatchNormalization(axis = chanDim)(x)\n",
    "        x = Dropout(.5)(x)\n",
    "        \n",
    "        # Apply another FC layer to match the nodes outputted by the MLP\n",
    "        x = Dense(4)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # check to see if the regression node should be added\n",
    "        if regress:\n",
    "            x = Dense(1, activation=\"linear\")(x)\n",
    "            \n",
    "        # construct the CNN\n",
    "        model = Model(inputs, x)\n",
    "        \n",
    "        # Return CNN\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firectory of the text file and columns of the data\n",
    "inputPath = '%s/HousesInfo.txt'%Data_Directory\n",
    "cols = ['bedrooms', 'bathrooms', 'area', 'zipcode', 'price']\n",
    "continuous_cols = ['bedrooms', 'bathrooms', 'area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>area</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2520</td>\n",
       "      <td>93446</td>\n",
       "      <td>789000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1802</td>\n",
       "      <td>93446</td>\n",
       "      <td>365000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2146</td>\n",
       "      <td>93446</td>\n",
       "      <td>455000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2464</td>\n",
       "      <td>91901</td>\n",
       "      <td>599000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1845</td>\n",
       "      <td>91901</td>\n",
       "      <td>529800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bedrooms  bathrooms  area  zipcode     price\n",
       "30         5        3.0  2520    93446  789000.0\n",
       "32         3        2.0  1802    93446  365000.0\n",
       "39         3        3.0  2146    93446  455000.0\n",
       "80         4        2.5  2464    91901  599000.0\n",
       "81         2        2.0  1845    91901  529800.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_house_attributes(inputPath, cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = load_house_images(df, Data_Directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing data...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] processing data...\")\n",
    "# Split into train and test data\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = train_test_split(df, images, test_size=0.25, random_state=42)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the largest house price in the training set and use it to\n",
    "# scale our house prices to the range [0, 1] (will lead to better\n",
    "# training and convergence)\n",
    "maxPrice = trainAttrX[\"price\"].max()\n",
    "trainY = trainAttrX[\"price\"] / maxPrice\n",
    "testY = testAttrX[\"price\"] / maxPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous COl ['bedrooms', 'bathrooms', 'area']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-c1b821146456>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrainAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAttrX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_house_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestAttrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontinuous_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-116-e1ddc5d423f4>\u001b[0m in \u001b[0;36mprocess_house_attributes\u001b[0;34m(df, train, test, continuous_columns)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Stack the data together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrainCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainContinuous\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestCategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainContinuous\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "(trainAttrX, testAttrX) = process_house_attributes(df, trainAttrX, testAttrX, continuous_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
