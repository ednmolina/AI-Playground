{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "Data is conveiently shaped numpy arrays. train_images are 60,000 images having dimensions of 28x28. There are 60,0000 orresponding training labels. The test set has similarly sized 10,000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Below is displayed what a typical image looks like in the dataset\n",
    "plt.figure(figsize = (4, 4))\n",
    "plt.imshow(train_images[4], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building blocks of neural networks are layers. Data processing occurs here and it can be thought of as a filter for data. Layers extract representations out of the data fed into them. Optimally many layers can be combined to form a process of data distillation.\n",
    "\n",
    "The network made here will be a sequence of two Dense layers (fully conected) neural layers. The second layer is a 10-way softmax layer, which means it will return an array of 10 probabilty scores. Each score will be the probability that the current digit image belongs to one of the 10 digit classes: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape_x, image_shape_y = np.shape(train_images)[1], np.shape(train_images)[2]\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(image_shape_x * image_shape_y,)))\n",
    "network.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define the loss function, the optimizer, and the meterics to monitor progress.\n",
    "\n",
    "The loss function measures how the network will be able to measure its own performance on the training images.\n",
    "\n",
    "The optimizer will be the mechanism which the network will use to update itself based on the data it is presented with.\n",
    "\n",
    "The metrics to monitor during training nad testing will be accuracy in this example which will be as a measure of the fraction of images that were correctly classified.\n",
    "\n",
    "categorical_crossentropy is the loss function that's used a feddback signal for leanring the weight tensors, and which the training phase will attempt to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Before we train the network we will preprocess the data by reshaping and scaling the data values between [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((np.shape(train_images)[0], image_shape_x*image_shape_y))\n",
    "train_images = train_images.astype('float32')/255.\n",
    "\n",
    "test_images = test_images.reshape((np.shape(test_images)[0], image_shape_x*image_shape_y))\n",
    "test_images = test_images.astype('float32')/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the labels\n",
    "The labels will be categorically encoded. The resulting train_labels will be shaped 60,000 x 10. to_categorical converts a vector of integers o a binary class matrix. Originally train_labels was a vector of shape 60,000, after to_categorical (60000x10).\n",
    "\n",
    "\n",
    "What originally was a 1 in the original vector can be represented as\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the model\n",
    "The network will start to iterate on the training data in the mini-batches of 128 samples, 5 times over. Aafter every iteration, the network will update the weights by computing the gradients of the weights with thregaurd to the loss function.\n",
    "\n",
    "After 5 batches, the netwrok should have performed 2, 345 gradient updates (469 persecond).\n",
    "\n",
    "We will fit the model to the training set and the new categorical labels we created above. We can see the accuracy of the model is about 98.91% on the training data. On the testing data, the model appears to be 98.08% accurate, alightly lower than the testing data. THe gap between the training and testing accuracy is an example of overfitting. The machine learning model performed worse on new data because the model becomes biased towards the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.2537 - acc: 0.9249\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.1034 - acc: 0.9698\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0669 - acc: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0496 - acc: 0.9846\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0370 - acc: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1405d9cc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 27us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the testing accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9773\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
